{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DrAiveX Day 2: Introduction to Python for Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Data Engineering and Why is Important\n",
    "\n",
    "_[Definition]_: Data Engineering is the process of converting the raw data from the datsets (CSV, XLS) etc into a form which the AI Model can Understand.\n",
    "\n",
    "AI/ Artificial Intelligence is the Computational use of Statistics. Since Statistics is  mathematical topic, including Numbers, So, Every AI Model, can work only on Numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sounds Cool! How to Convert every data into Numbers?\n",
    "\n",
    "In Data Engineering is not only about representing non-numeric data into numbers, It includes additional important steps like,Data Cleaning, Plotting to find the nature of Data, etc. As the answer of the question, We Represent limited set of Non-Numeric Properties (like Gender, Department in college, etc) as Numbers, like (0/1 for Gender, Set of Natural Numbers as the Departments (0,1,2,3...,n) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay! I get it, but I am too lazy to create a set of rules to, read the data, access the data,  What Do I Do? :3\n",
    "\n",
    "In python there's a lots of libraries that can help you in the process of Data Engineering,and Normalizing. Two of the famous ones are (We wil use use them extensively):\n",
    "* Numpy (Numeric Python, To handle matrix calculations, so that you don't have to worry about the Algorithms behind it)\n",
    "* Pandas (To Handle filtering, Normalizing, reading/writing to/from widely used dataset formats like CSV, XLS files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OMG !! I don't know Python!! What to Do??\n",
    "\n",
    "Well, My friend, Python is a very _Funny Language_ (Quoting from Bol Bachhan, Haha!!). It is easy to use, hassle free code, and anyone can understand Python, if they got a basic logical sense, and knows a bit of english.\n",
    "\n",
    "Even the Hello world of Python is so easy!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See?? No extra lines of Stuffs, and so much intutive!\n",
    "If you guys know, Basic C programming, You will remember those notorious symbols like `;`, `{`. Well, in python,\n",
    "\n",
    "##### We Don't have it here!!\n",
    "And To Symbolize  Block, you just need to provide a Tab or some spaces to align the code, and creating blocks like it was done in `{` in C. _(Even There's not `int`, `float`, `char` datatypes, Pyhton is smart enough to understand the datatype. ;) )_ **Okay!** Enough, Chit Chat, Let me show you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a= 10\n",
    "if a %2 ==9:\n",
    "    print(\"Even\")\n",
    "else:\n",
    "    print(\"Odd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You only need to know these to get started to your data science career! Rest you can learn as you go! **PS :Don't tell anyone.. I did this approach myself.. haha!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And through out your Python Career if you come across some Functions, Classes, you don't know, You can always open help from the python interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function hex in module __builtin__:\n",
      "\n",
      "hex(...)\n",
      "    hex(number) -> string\n",
      "    \n",
      "    Return the hexadecimal representation of an integer or long integer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For example, if you don't know w\n",
    "help(hex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in C/C++ we can write comments in the code, so that, it is easy for third person to read the code.\n",
    "Similar to every language, Comment doesn't get executed and python interpreter overlooks comment, as if they were not even present!\n",
    "** SO How do we write a comment? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HI! I'm a Comment! I don't get executed. I'm so lonely, no one (except the humans) cares about my existence :(\n",
    "print(\"Hello There!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas (Part 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install pandas from Jupyter Notebook, run the cell below (Press Ctrl-Enter while in the Cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! pip install pandas\n",
    "! pip install xlrd #For reading excel Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That was easy right?? ;)\n",
    "Moving right along, Let's see how to open dataset files using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/_libs/__init__.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/__init__.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (hashtable as _hashtable,\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/dtypes/common.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/util/hashing.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import hashing, tslib\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/indexes/base.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, index as libindex, tslib as libts,\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/tseries/offsets.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.tslibs.offsets as liboffsets\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/ops.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as libalgos, ops as libops\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/indexes/interval.py:32: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs.interval import (\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/internals.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import internals as libinternals\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/sparse/array.py:33: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.sparse as splib\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/window.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.window as _window\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/groupby/groupby.py:68: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import (lib, reduction,\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/reshape/reshape.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos as _algos, reshape as _reshape\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  import pandas._libs.parsers as parsers\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/io/pytables.py:50: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from pandas._libs import algos, lib, writers as libwriters\n"
     ]
    }
   ],
   "source": [
    "# lets call pandas in the code at first ( Like #include in C/C++ )\n",
    "import pandas as pd\n",
    "# import calls the library pandas we installed previously. we could've written import pandas but then if we had\n",
    "# to use anything from pandas library, we needed to callit as pandas.function() but we are lazy right? ;)\n",
    "# so we used the as keyword of python which sets a nickname (alias) for pandas, pd. so, that next time we call\n",
    "# anything, we can call it as pd.function() instead of pandas.function()\n",
    "# Easy right ;)\n",
    "\n",
    "\n",
    "#variable1=pd.read_csv(\"test.csv\") If you have a .csv file, use this\n",
    "variable1=pd.read_excel(\"titanic3.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Congrats! You have successfully read the titanic3.xls file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find more about `read_csv` file, by typing this out in a code cell / Python interpreter:\n",
    "```python\n",
    "help(pd.read_csv)\n",
    "```\n",
    "`variable1` in above code is called **DataFrame** according to Pandas Convention.\n",
    "\n",
    "Now let's see, what kind of dataset we have got, let's see some of the top entries (In this case top 10 entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  survived                                             name     sex  \\\n",
      "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
      "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
      "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
      "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
      "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
      "5       1         1                              Anderson, Mr. Harry    male   \n",
      "6       1         1                Andrews, Miss. Kornelia Theodosia  female   \n",
      "7       1         0                           Andrews, Mr. Thomas Jr    male   \n",
      "8       1         1    Appleton, Mrs. Edward Dale (Charlotte Lamson)  female   \n",
      "9       1         0                          Artagaveytia, Mr. Ramon    male   \n",
      "\n",
      "       age  sibsp  parch    ticket      fare    cabin embarked boat   body  \\\n",
      "0  29.0000      0      0     24160  211.3375       B5        S    2    NaN   \n",
      "1   0.9167      1      2    113781  151.5500  C22 C26        S   11    NaN   \n",
      "2   2.0000      1      2    113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "3  30.0000      1      2    113781  151.5500  C22 C26        S  NaN  135.0   \n",
      "4  25.0000      1      2    113781  151.5500  C22 C26        S  NaN    NaN   \n",
      "5  48.0000      0      0     19952   26.5500      E12        S    3    NaN   \n",
      "6  63.0000      1      0     13502   77.9583       D7        S   10    NaN   \n",
      "7  39.0000      0      0    112050    0.0000      A36        S  NaN    NaN   \n",
      "8  53.0000      2      0     11769   51.4792     C101        S    D    NaN   \n",
      "9  71.0000      0      0  PC 17609   49.5042      NaN        C  NaN   22.0   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n",
      "5                     New York, NY  \n",
      "6                       Hudson, NY  \n",
      "7                      Belfast, NI  \n",
      "8              Bayside, Queens, NY  \n",
      "9              Montevideo, Uruguay  \n"
     ]
    }
   ],
   "source": [
    "print(variable1.head(10)) # printing top n=10 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's cool! Now it's time to look at different properties of data. That might help us identify some deeper meaning from the data, helping us to engineer the data properly.\n",
    "### But, I AM LAZY! I don't wanna write any code to find out those stuffs! What to Do?\n",
    "Well, my friend, I am lazy too! and pandas knows it very well! haha! So, it has provided this extremely important function, that can give us all those nerdy stuffs, we want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            pclass     survived          age        sibsp        parch  \\\n",
      "count  1309.000000  1309.000000  1046.000000  1309.000000  1309.000000   \n",
      "mean      2.294882     0.381971    29.881135     0.498854     0.385027   \n",
      "std       0.837836     0.486055    14.413500     1.041658     0.865560   \n",
      "min       1.000000     0.000000     0.166700     0.000000     0.000000   \n",
      "25%       2.000000     0.000000    21.000000     0.000000     0.000000   \n",
      "50%       3.000000     0.000000    28.000000     0.000000     0.000000   \n",
      "75%       3.000000     1.000000    39.000000     1.000000     0.000000   \n",
      "max       3.000000     1.000000    80.000000     8.000000     9.000000   \n",
      "\n",
      "              fare        body  \n",
      "count  1308.000000  121.000000  \n",
      "mean     33.295479  160.809917  \n",
      "std      51.758668   97.696922  \n",
      "min       0.000000    1.000000  \n",
      "25%       7.895800   72.000000  \n",
      "50%      14.454200  155.000000  \n",
      "75%      31.275000  256.000000  \n",
      "max     512.329200  328.000000  \n"
     ]
    }
   ],
   "source": [
    "print(variable1.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See! Easy right? Okay now the most important question, you might have.\n",
    "### Okay, I get it. Pandas is cool, But how can I get the data that pandas is showing for further manipulation?\n",
    "\n",
    "Well, my friend, that's why we are here!\n",
    "But First Let's get some introduction to Python List and Dictionary ** The Pandas Story is not over yet! **\n",
    "If you know about Python List and Dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python List and Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we all know, to store any data we need a variable. **But Wait!** if there are thousands of same **type** of data,\n",
    "** DO WE NEED TO DECLARE THOUSANDS OF VARIABLES?? ARRGH!!!!**\n",
    "Well, haha! That's not the case, Python have something called **List**, Similar to arrays in C/C++ pr whatever language you have seen yet.\n",
    "_[Def]_: List is a kind of Varible which can store a lot of data in a single variable, **With No Limitations** of the **Datatype** of the content data. (Which was in the case of C/C++/C#/Java Arrays).\n",
    "List a collection of data which can store any type of data together!  (People with Java Background, It's simialar to ArrayList in Java Collections)\n",
    "\n",
    "_**Example**_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<type 'str'>\n",
      "<type 'int'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "variable2=[\"Adrish\", 1234, variable1]\n",
    "# Here \"Adrish is a String, 1234 is a number (int) and variable is a pandas DataFrame Object\n",
    "# But our List can store them all!\n",
    "print(type(variable2)) # <class 'list'>\n",
    "# lists like arrays have zero-base indexing, where 0 represents 1st element, 1 represents 2nd element etc.\n",
    "print(type(variable2[0])) # <class 'str'>\n",
    "print(type(variable2[1])) # <class 'int'>\n",
    "print(type(variable2[2])) # <class 'pandas.core.frame.DataFrame'>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, Adrish, I couldn't follow the Comments and I need a better description of Python List. What are those numbers in the 3rd brackets!\n",
    "They are indexes of element in the list.\n",
    "Okay, let me show you an example:\n",
    "Let `a` be a python list.\n",
    "```python\n",
    "a = [1, 2, 3, 4]\n",
    "```\n",
    "This list is represented in the memory as:\n",
    "```sh\n",
    "[   1    |   2    |    3     |   4   ]\n",
    "    ^        ^         ^         ^\n",
    "    0        1         2         3      <--- Hello! We are indexes!\n",
    "```\n",
    "A computer alway starts counting from 0, so, the position of the 1st element of the list is 0, 2nd element is 1 etc.\n",
    "and when we say `a[0]` we are asking python to give us the element from the list `a` which is located at position 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Dictionary\n",
    "Whenever I talk about dictionary, What comes to your mind?? For me, It's the Oxford Pocket Dictionary, I have (It has been a life saver you know!, Haha!)\n",
    "\n",
    "so, what happens in that oxford pocket dictionary? We search for the word and we get all the syntactical and symantical information we need to know about the word.\n",
    "So, if I ask you, how will you implement that in any language??\n",
    "\n",
    "I am sure, many will tell that we will save the Words in an Array and We will save the meanings in other arrays, and we will use the indexes to match them.\n",
    "The word at 0th position of the array1 will have it's meaning in array2 in the same 0th position, so on and so forth.\n",
    "**OR**\n",
    "you can use python dictionaries!\n",
    " ** Okay, HOW??**\n",
    " python dictionaries looks like this:\n",
    "```python \n",
    " \n",
    " dictionary = {\"cat\":\"A cute furry animal, which loves humans\", \"dog\":\"4 legged mammal, which are cute when small and bold when grows older.\"}\n",
    " \n",
    " ```\n",
    " \n",
    " **Okay, I get it, but how to access the descriptions of the word \"cat\" ?**\n",
    " \n",
    " Well, my friend, it's so damn easy!\n",
    " \n",
    " ```python\n",
    " \n",
    " print(dictionary[\"cat\"])\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cute furry animal, which loves humans\n"
     ]
    }
   ],
   "source": [
    "dictionary = {\"cat\":\"A cute furry animal, which loves humans\", \"dog\":\"4 legged mammal, which are cute when small and bold when grows older.\"}\n",
    "print(dictionary[\"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas (Continued)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to access data from Pandas DataFrame?\n",
    "Pandas DataFrame Provides a similar access technique as Dictionary and List Combined.\n",
    "The Pandas DataFrame is like a Matrix, with rows and columns. \n",
    "We need to pass the name of the column and the row number to get the data.\n",
    "the syntax is:\n",
    "`dataFrame[<Column Name>][<ROw Number>]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name Stream Sex Section\n",
      "0  Adrish    CSE   M       B\n",
      "1  Soumit    CSE   M       A\n",
      "2  Shahid    CSE   M       A\n",
      "3   Soham    CSE   M       A\n",
      "4   Ayush    ECE   M       A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Adrish\n"
     ]
    }
   ],
   "source": [
    "test_df=pd.read_csv(\"test.csv\")\n",
    "print(test_df)\n",
    "print(\"\\n\"*4)\n",
    "print(test_df[\"Name\"][0]) # Print the First Name from the CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "The example works perfectly, If the columns are given a name. Ase we saw the Columns are accessed by passing the name of the column and the number of the row.**However**, if there are no column header, we need to tell`pd.read_csv` explicitly, that there are no headers, otherwise, it will consider, the first entry as header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Adrish  CSE  M  B\n",
      "0  Soumit  CSE  M  A\n",
      "1  Shahid  CSE  M  A\n",
      "2   Soham  CSE  M  A\n",
      "3   Ayush  ECE  M  A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('1st Column:', 0    Soumit\n",
      "1    Shahid\n",
      "2     Soham\n",
      "3     Ayush\n",
      "Name: Adrish, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# For example\n",
    "test_df=pd.read_csv(\"no_header.csv\")\n",
    "print(test_df)\n",
    "print(\"\\n\"*4)\n",
    "print(\"1st Column:\",test_df['Adrish'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the first element, \"Adrish\" is now considered as column name, which is np=ot what we want, right?\n",
    "In such cases, we need to pass `pd.read_csv()` another _parameter_, `header=None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1  2  3\n",
      "0  Adrish  CSE  M  B\n",
      "1  Soumit  CSE  M  A\n",
      "2  Shahid  CSE  M  A\n",
      "3   Soham  CSE  M  A\n",
      "4   Ayush  ECE  M  A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('1st Column: ', 0    Adrish\n",
      "1    Soumit\n",
      "2    Shahid\n",
      "3     Soham\n",
      "4     Ayush\n",
      "Name: 0, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "test_df=pd.read_csv(\"no_header.csv\",header=None)\n",
    "print(test_df)\n",
    "print(\"\\n\"*4)\n",
    "print(\"1st Column: \", test_df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we want something more:\n",
    "Let's find out some more stuffs about pandas.\n",
    "To find the maximum/ minimum value of a column:\n",
    "there's a function, called `max()/min()` respectively which can help us with that.\n",
    "\n",
    "** Now, How to use it?? **\n",
    "\n",
    "`dataFrame[<column name>].max()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum:  80.0\n",
      "Minimum:  0.1667\n"
     ]
    }
   ],
   "source": [
    "print \"Maximum: \",variable1['age'].max()\n",
    "print \"Minimum: \",variable1['age'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Collection of Data from the DataFrame, which staisfies some given condition\n",
    "Here we will see how to get a list of Rows from the DataFrame, whose column satisfies a specific condition.\n",
    "\n",
    "** Adrish! That went tangential to my head! Can you rephrase?**\n",
    "\n",
    "For Example, in the dataset we are using, titanic passenger dataset, let us assume, we want to know how many of the passengers are alive. According to the dataset, we want to know the **Name and Age** of the people, whose survival column have value =1\n",
    "How to do that??\n",
    "\n",
    "** PS: Being a Lazy Person, I don't want write the code which will loop thtough all the Rows and print those columns which have survive==1 **\n",
    "\n",
    "Hmm.... What to do now??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, Pandas Knows we are **lazy** so it provided this awesome feature, to solve this kind of problem.\n",
    "\n",
    "```python\n",
    "dataFrame[<column_name(s)_ to_fetch>][<condition>]\n",
    "```\n",
    "**Example Time!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Name'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d878e2f79930>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfiltered_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariable1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Name\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"age\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariable1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"survived\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# The Dataset is huge, so we are looking the top 10 entries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Name'] not in index\""
     ]
    }
   ],
   "source": [
    "filtered_1=variable1[[\"Name\",\"age\"]][variable1[\"survived\"]==1]\n",
    "print(filtered_1.head(10))# The Dataset is huge, so we are looking the top 10 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FillNaN\n",
    "In real life Datasets, There are cases, where some of the entries are missing. For Example: In our dataset, there are places where the Parchment number of the victims are not present, and those places are filled with a special numerical value, called NaN (Not a Number). These NaNs cannot help in performing any Mathematical operation, so our AI model will suddenly crashed if these NaNs are not removed.\n",
    "** Solution 1: ** Wite an Program which will loop through all elements and replace these NaNs with any number we wish (generally 0)\n",
    "\n",
    "** PS: We Are Lazy! Aren't We?. And the best part, Pandas Knows it! **\n",
    "So we have this amazing function which helps us get our job done! ;)\n",
    "Let me show you an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(variable1.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can You see those Vacant Places?? (Filled with NaN)\n",
    "Let's fill those holes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable1.fillna(0,inplace=True)\n",
    "print(variable1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can You Spot the difference now?**\n",
    "\n",
    "`.fillna()` takes one argument, the value to fill the vacant places with. `inplace=True` is used to make the changes in `variable1` instead of keeping it unmodified and returning a modified DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember those times, when we had to write for loops in C while performing matrix calculation? Aargh! I hated to write ~20 lines for performing matrix multiplications/addition/substraction.\n",
    "So for us Lazy People, There's this awesome Library in Python known as **Numpy** which stands for Numeric Python.\n",
    "\n",
    "\n",
    "Numpy can perform a whole lot of functions,but it's speciality stands out in it's extremely easy interface for performing operations on matrix and numeric arrays.\n",
    "\n",
    "### Ok, how to use it??\n",
    "To use it you need to install it first. The following code cell can help you with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Okay that was easy!**\n",
    "\n",
    "Now how to use this? AKA, **Adrish Show me some Magic!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we need to import it first right? :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # Okay! Don't judge me, I'm lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array1=np.array([1,2,3,4,5,6])\n",
    "array2=np.array([1]*6) # You can do this, to flaunt your lazy nature, this [1]*6 creates a list of 6, 1s, [1,1,1,1,1,1]\n",
    "#Adding 2 numbers\n",
    "print(array1+array2) #See that was easy!!!!!!!\n",
    "print(array1-array2) # EEEEAAASSSYYYYY!!!!!!\n",
    "print(array1*array2) #Perform element wise multiplication: That was easy too!\n",
    "print(array1/(2*array2)) # You can even multiply a scalar like 2 with array2, with no extra headache.. and you can divide it.. just like numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There a **LOT** More numpy, but this much is enough for Project 1.\n",
    "\n",
    "I'm on a train, shaking like crazy, and people are staring, as I am doing something illegal.. before anyone says anything, let me sign off!\n",
    "See you Next time..\n",
    "\n",
    "Adrish Dey"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
